{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBSqZAvJ0bsUmYUp4cBA4a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matheusBernal/Detection-Faces/blob/main/DetectionFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYqoU7bHBExa",
        "outputId": "3e60b8e7-0abc-41e6-8260-b1fb4daaa30d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python opencv-python-headless opencv-contrib-python tensorflow matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from PIL import Image\n",
        "import os\n",
        "import cv2.data\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import zipfile\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "ojkEHFtFBUD7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zipRef = zipfile.ZipFile(\"/content/data.zip\", 'r')\n",
        "zipRef.extractall()\n",
        "zipRef.close()"
      ],
      "metadata": {
        "id": "iWf4wkKZCCTu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/data/train'\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "for name in os.listdir(train_dir):\n",
        "    path_class = train_dir+'/'+name\n",
        "    for photo_name in os.listdir(path_class):\n",
        "        path_name_class = path_class+'/'+photo_name\n",
        "        image = cv2.imread(path_name_class)\n",
        "        gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray,scaleFactor=1.2,minNeighbors=4,minSize=(50,50))\n",
        "        for i,(x,y,w,h) in enumerate(faces):\n",
        "            Y = y+h\n",
        "            X = x+w\n",
        "            face = image[y:Y,x:X]\n",
        "            face_resized = cv2.resize(face,(128,128))\n",
        "            face_filename = f\"/content/data/train_faces/{name}/{photo_name}\"\n",
        "            face_filename_valid = f\"/content/data/valid/{name}/{photo_name}\"\n",
        "            cv2.imwrite(face_filename,face_resized)\n",
        "            cv2.imwrite(face_filename_valid,face_resized)"
      ],
      "metadata": {
        "id": "ZYeqW4XdRXGE"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAING_FACES_DIR = '/content/data/train_faces'\n",
        "VALID_DIR = '/content/data/valid'\n",
        "\n",
        "training_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "0a1Yh45LCI2f"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_generator = training_datagen.flow_from_directory(TRAING_FACES_DIR,target_size=(300, 300),batch_size=30,class_mode='categorical')\n",
        "validation_generator = validation_datagen.flow_from_directory(VALID_DIR,target_size=(300, 300),batch_size=30,class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJDmeUdLCPl8",
        "outputId": "a4d3e3fb-7fe0-4df6-8ca8-3cc8536c45ce"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 125 images belonging to 6 classes.\n",
            "Found 125 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(300,300,3)),\n",
        "    tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512,activation='relu'),\n",
        "    tf.keras.layers.Dense(len(training_generator.class_indices),activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "G_JAHrNDCSst"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(training_generator,validation_data=validation_generator,epochs=26)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j56mYWhzCWsS",
        "outputId": "a1c67039-967a-48cf-8803-e5911f8f231e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 25s/step - accuracy: 0.0860 - loss: 1.7960 - val_accuracy: 0.1680 - val_loss: 1.7911\n",
            "Epoch 2/26\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25s/step - accuracy: 0.1567 - loss: 1.7943 - val_accuracy: 0.1680 - val_loss: 1.7907\n",
            "Epoch 3/26\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 25s/step - accuracy: 0.1441 - loss: 1.7911 - val_accuracy: 0.1680 - val_loss: 1.7892\n",
            "Epoch 4/26\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 24s/step - accuracy: 0.1710 - loss: 1.7918 - val_accuracy: 0.1680 - val_loss: 1.7890\n",
            "Epoch 5/26\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 28s/step - accuracy: 0.1671 - loss: 1.7879 - val_accuracy: 0.2800 - val_loss: 1.7874\n",
            "Epoch 6/26\n",
            "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m16s\u001b[0m 17s/step - accuracy: 0.2805 - loss: 1.7862"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(accuracy))"
      ],
      "metadata": {
        "id": "D84CUZ4mCZue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs,accuracy,'r',label='Training accuracy')\n",
        "plt.plot(epochs,val_accuracy,'b',label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xj5W1jX4CeVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs,loss,'r',label='Training loss')\n",
        "plt.plot(epochs,val_loss,'b',label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IQRam_K4CgPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "def classificationImage(i):\n",
        "    path_image = f\"/content/data/test/{i}.jpg\"\n",
        "    image_loaded= image.load_img(path_image,target_size=(300,300))\n",
        "    img_array = image.img_to_array(image_loaded)\n",
        "    img_array = np.expand_dims(img_array,axis=0)\n",
        "    img_array = np.vstack([img_array])\n",
        "    predict = history.model.predict(img_array,batch_size=10)\n",
        "    if predict[0][0]!=0:\n",
        "        return \"Amy\"\n",
        "    elif predict[0][1] !=0:\n",
        "        return 'Bernadete'\n",
        "    elif predict[0][2] !=0:\n",
        "        return 'Leonard'\n",
        "    elif predict[0][3] !=0:\n",
        "        return 'Penny'\n",
        "    elif predict[0][4] !=0:\n",
        "        return 'Raj'\n",
        "    else:\n",
        "        return 'Sheldon'"
      ],
      "metadata": {
        "id": "f5C02S_fCi71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "image_cast = cv2.imread('/content/data/test/Cast.jpeg')\n",
        "gray = cv2.cvtColor(image_cast,cv2.COLOR_BGR2GRAY)\n",
        "faces = face_cascade.detectMultiScale(gray,1.8,minNeighbors=4,minSize=(30,30))\n",
        "for i,(x,y,w,h) in  enumerate(faces):\n",
        "    #cv2.rectangle(image_cast,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    Y = y+h\n",
        "    X = x+w\n",
        "    face = image_cast[y:Y,x:X]\n",
        "    #cv2.imshow('Image cast',face)\n",
        "    #cv2.waitKey(0)\n",
        "    #cv2.destroyAllWindows()\n",
        "    face_resized = cv2.resize(face,(300,300))\n",
        "    face_filename = f\"/content/data/test/{i}.jpg\"\n",
        "    cv2.imwrite(face_filename,face_resized)\n",
        "    name_classification = classificationImage(i)\n",
        "    cv2.rectangle(image_cast,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "    cv2.putText(image_cast,name_classification,(x,y),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2)\n",
        "cv2.imwrite('/content/output_image.jpg', image_cast)\n",
        "#cv2.imshow(image_cast)"
      ],
      "metadata": {
        "id": "YxCsdRWNCm1v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}